---

- name: Deploy Scaphandre
  hosts: localhost
  connection: local
  gather_facts: false
  roles:
    - "scaphandre"


- name: Patch Prometheus CRD
  hosts: localhost
  connection: local
  gather_facts: false
  tasks:
    - name: Update Prometheus CRD and Re-enable monitoring
      k8s:
        state: present
        definition:
          api: monitoring.coreos.com/v1
          kind: Prometheus
          metadata:
            namespace: default
            name: kp-kube-prometheus-stack-prometheus
          spec:
            externalLabels:
              deployment_started_ts: "{{ deployment_started_ts }}"
              experiment_started_ts: "{{ experiment_started_ts }}"
            remoteWrite:
              - url: "{{ lookup('ansible.builtin.env', 'EXPERIMENT_STORAGE_URL') }}"
            replicas: 1

    - name: Wait until Scaphandre Daemonset is online
      shell: "kubectl -n default rollout status ds/scaphandre"
      register: output
      until: output.stdout.find("successfully rolled out") != -1
      retries: 20
      delay: 15

    - name: Wait for the specified number of replicas to become ready
      k8s_info:
        api: monitoring.coreos.com/v1
        kind: Prometheus
        name: kp-kube-prometheus-stack-prometheus
        namespace: default
      register: deployment_info
      until: deployment_info.resources[0].status.availableReplicas == deployment_info.resources[0].spec.replicas
      retries: 20
      delay: 2

    - name: Create Kafka Topic via Job
      kubernetes.core.k8s:
        state: present
        namespace: default
        definition:
          apiVersion: batch/v1
          kind: Job
          metadata:
            name: create-kafka-topic
          spec:
            ttlSecondsAfterFinished: 5
            backoffLimit: 1
            template:
              spec:
                containers:
                  - name: create-topic
                    image: redpandadata/redpanda
                    command: ["rpk"]
                    args:
                      - "topic"
                      - "create"
                      - "input"
                      - "-p"
                      - "{{ exp_params.partitions }}"
                      - "-X"
                      - "brokers={{ exp_params.kafka_bootstrap_servers }}"
                restartPolicy: Never


- name: Deploy EXP
  hosts: localhost
  connection: local
  gather_facts: false
  roles:
    - "{{ exp_name }}"

- name: Wrap up Experiment
  hosts: localhost
  connection: local
  gather_facts: false
  tasks:
{% if 'ingest' not in exp_name  %}
    - name: Wait for execution to finish
      shell: kubectl wait execution "{{ exp_name }}" --for=jsonpath='{.status.executionState}'=Finished --timeout=1h

    - name: Delete any past experiment
      kubernetes.core.k8s:
        state: absent
        api_version: theodolite.rocks/v1beta1
        kind: execution
        namespace: default
        name: "{{ exp_name }}"
{% else %}
    - name: Sleep for {{ exp_params.durationSeconds }} seconds
      pause:
        seconds: {{ exp_params.durationSeconds }}
    - name: Delete Load generator deployment
      kubernetes.core.k8s:
        state: absent
        api_version: apps/v1
        kind: Deployment
        namespace: default
        name: throughput

    - name: Delete Kafka Topic via Job
      kubernetes.core.k8s:
        state: present
        namespace: default
        definition:
          apiVersion: batch/v1
          kind: Job
          metadata:
            name: delete-kafka-topic
          spec:
            ttlSecondsAfterFinished: 5
            backoffLimit: 4
            template:
              spec:
                containers:
                  - name: delete-topic
                    image: redpandadata/redpanda
                    command: ["rpk"]
                    args:
                      - "topic"
                      - "delete"
                      - "input"
                      - "-X"
                      - "brokers={{ exp_params.kafka_bootstrap_servers }}"
                restartPolicy: Never
{% endif %}

    # Scale down the daemonset
    - name: Delete all scaphandre
      shell: kubectl delete -l app.kubernetes.io/name=scaphandre serviceaccount,daemonset,servicemonitor,clusterrole,clusterrolebinding,service --force --grace-period=0
      ignore_errors: true

    - name: Give it 10 seconds to cool down
      pause:
        seconds: 10

# TODO: Once everything is well understood, we can start scaling down Prometheus once again
    - name: Scale down Prometheus to 0
      k8s:
        state: present
        definition:
          api: monitoring.coreos.com/v1
          kind: Prometheus
          metadata:
            namespace: default
            name: kp-kube-prometheus-stack-prometheus
          spec:
            replicas: 0

    - name: Give it 10 seconds to cool down
      pause:
        seconds: 10
